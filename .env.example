# Required
DATABASE_URL=sqlite:////mnt/options_ai/database/predictions.db
TICKER=SPX
DATA_ROOT=/mnt/options_ai

# Remote model (OAuth) - used when OAuth configured and token succeeds
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
OAUTH_TOKEN_URL=
OAUTH_SCOPE=
# Optional
OAUTH_AUDIENCE=
OAUTH_REFRESH_MARGIN_SECONDS=60
OAUTH_CACHE_PATH=/mnt/options_ai/state/oauth_token.json
REMOTE_MODEL_NAME=openai-codex/gpt-5.2

# Local model (OpenAI-compatible; trusted LAN)
LOCAL_MODEL_ENABLED=true
LOCAL_MODEL_ENDPOINT=http://192.168.86.24:11434/v1
LOCAL_MODEL_NAME=deepseek-r1:8b
LOCAL_MODEL_TIMEOUT_SECONDS=60
LOCAL_MODEL_MAX_RETRIES=2

# Routing overrides
MODEL_FORCE_LOCAL=false
MODEL_FORCE_REMOTE=false

# Optional tuning
MIN_CONFIDENCE=0.65
OUTCOME_DELAY=15
HISTORY_RECORDS=10
# When provider=local, default to smaller context to reduce tokens/latency
LOCAL_HISTORY_RECORDS=3
SIMILAR_CONDITIONS_N=3

# Backtesting / event-time (v2.5)
BACKTEST_MODE=false
# Recommended: disable chart extraction in backtests for speed/consistency
BACKTEST_DISABLE_CHART=true

# Tokens estimation (v2.6)
# DeepSeek endpoint doesn't return usage, so we estimate from chars.
TOKENS_PER_CHAR=0.25
TOKENS_ESTIMATION_MODE=chars

# Output token caps (v2.4)
PREDICTION_MAX_OUTPUT_TOKENS=300
CHART_MAX_OUTPUT_TOKENS=160

# Prompts (v2.4)
# Use compact system prompt for local deepseek to reduce prompt chars/latency
USE_COMPACT_SYSTEM_PROMPT_LOCAL=true

# Chart extraction gating (v2.4)
# Default off for local deployments (chart is an extra model call and image input is slow locally)
CHART_ENABLED=false
CHART_LOCAL_ENABLED=false
CHART_REMOTE_ENABLED=true

# GEX prompt compression (v2.3+)
GEX_NEIGHBOR_STRIKES=2
GEX_TOPK_ABS_STRIKES=0
GEX_STICKY_DAY_MAX=20
FILE_STABLE_SECONDS=2
WATCH_POLL_SECONDS=1
REPLAY_MODE=false

# Bootstrap
BOOTSTRAP_ENABLE=true
BOOTSTRAP_MAX_MODEL_CALLS_PER_MIN=0
BOOTSTRAP_MAX_MODEL_CALLS_PER_HOUR=0

# Caching / reprocessing
# none|from_model|from_summary|from_signals|full
REPROCESS_MODE=none

# Versioning
PROMPT_VERSION=v2.3.0

# Deprecated: OPENAI_API_KEY is ignored
# OPENAI_API_KEY=

# Logging (v2.3)
LOG_LEVEL=INFO
