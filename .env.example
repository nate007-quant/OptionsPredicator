# Required
DATABASE_URL=sqlite:////mnt/options_ai/database/predictions.db
TICKER=SPX
DATA_ROOT=/mnt/options_ai

# Remote model (OAuth) - used when OAuth configured and token succeeds
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
OAUTH_TOKEN_URL=
OAUTH_SCOPE=
# Optional
OAUTH_AUDIENCE=
OAUTH_REFRESH_MARGIN_SECONDS=60
OAUTH_CACHE_PATH=/mnt/options_ai/state/oauth_token.json
REMOTE_MODEL_NAME=openai-codex/gpt-5.2

# Local model (OpenAI-compatible; trusted LAN)
LOCAL_MODEL_ENABLED=true
LOCAL_MODEL_ENDPOINT=http://192.168.86.24:11434/v1
LOCAL_MODEL_NAME=deepseek-r1:8b
LOCAL_MODEL_TIMEOUT_SECONDS=60
LOCAL_MODEL_MAX_RETRIES=2

# Routing overrides
MODEL_FORCE_LOCAL=false
MODEL_FORCE_REMOTE=false

# Optional tuning
MIN_CONFIDENCE=0.65
OUTCOME_DELAY=15
HISTORY_RECORDS=10
# When provider=local, default to smaller context to reduce tokens/latency
LOCAL_HISTORY_RECORDS=3
SIMILAR_CONDITIONS_N=3

# Backtesting / event-time (v2.5)
BACKTEST_MODE=false
BACKTEST_DISABLE_CHART=true

# Tokens estimation (v2.6)
TOKENS_PER_CHAR=0.25
TOKENS_ESTIMATION_MODE=chars

# ML (v2.7)
ML_ENABLED=false
LLM_ENABLED=true
ML_MODELS_DIR=/mnt/options_ai/models
ML_MODEL_VERSION=ml_v1
ML_FEATURES_VERSION=ml_features_v1
ML_ACTION_THRESHOLD=0.85
ML_MIN_NEUTRAL_BAND_PTS=3.0
ML_K_EM=0.20

# Output token caps (v2.4)
PREDICTION_MAX_OUTPUT_TOKENS=300
CHART_MAX_OUTPUT_TOKENS=160

# Prompts (v2.4)
USE_COMPACT_SYSTEM_PROMPT_LOCAL=true

# Chart extraction gating (v2.4)
CHART_ENABLED=false
CHART_LOCAL_ENABLED=false
CHART_REMOTE_ENABLED=true

# GEX prompt compression (v2.3+)
GEX_NEIGHBOR_STRIKES=2
GEX_TOPK_ABS_STRIKES=0
GEX_STICKY_DAY_MAX=20
FILE_STABLE_SECONDS=2
WATCH_POLL_SECONDS=1
PAUSE_PROCESSING=false
REPLAY_MODE=false

# Bootstrap
BOOTSTRAP_ENABLE=true
BOOTSTRAP_MAX_MODEL_CALLS_PER_MIN=0
BOOTSTRAP_MAX_MODEL_CALLS_PER_HOUR=0

# Caching / reprocessing
REPROCESS_MODE=none

# Versioning
PROMPT_VERSION=v2.3.0

# Logging (v2.3)
LOG_LEVEL=INFO

# Admin reset (dangerous)
RESET_ENABLED=false
